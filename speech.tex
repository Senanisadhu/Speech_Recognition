\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\title{Speech Command Model}
\author{SENANI SADHU}
\date{\today}
\begin{document}
	\maketitle
	\newpage
	\section{Language Used:}
	Python
	\section{Libraries and packages used:}
	KAPRE , SCIKIT LEARN , SOUND FILE , TENSORFLOW.
	\section{Overview:}
	Speech Command Recognition is changing voices in to text form,Speech
	command recognition is present in a wide range of devices and utilized
	by many HCI interfaces. In many situations, it is desirable to obtain
	lightweight and high accuracy models that can run locally.
	Some speech recognition systems require ”training” (also called ”enrollment”) where an individual speaker reads text or isolated vocabulary into
	the system. The system analyzes the person’s specific voice and uses it
	to fine-tune the recognition of that person’s speech, resulting in increased
	accuracy. Systems that do not use training are called ”speaker independent”[1] systems. Systems that use training are called ”speaker dependent”.
	Speech recognition applications include voice user interfaces such as voice
	dialing (e.g. ”call home”), call routing (e.g. ”I would like to make a
	collect call”), domotic appliance control, search key words (e.g. find a
	podcast where particular words were spoken), simple data entry (e.g., entering a credit card number), preparation of structured documents (e.g.
	a radiology report), determining speaker characteristics,[2] speech-to-text
	processing (e.g., word processors or emails), and aircraft (usually termed
	direct voice input).
	\section{DATA:}
	\begin{itemize}
		\item Set 16KHz as sampling rate.
		\item Record 80 utterances of each command.
		\item Save samples of each command in different folders.
		\begin{enumerate}
			\item Dataset/Forward.
			\item Dataset/Back.
			\item Dataset/Left.
			\item Dataset/Right.
			\item Dataset/Stop.
		\end{enumerate}
	\end{itemize}
\section{Description:-}
\begin{enumerate}
	\item Using Convolutional layers ahead of LSTM is shown to improve performance in several research papers.
	\item BatchNormalization layers are added to improve convergence rate.
	\item Using Bidirectional LSTM is optimal when complete input is available. But this increases the runtime two-fold.
	\item Final output sequence of LSTM layer is used to calculate importance of units in LSTM using a FC layer.
	\item Then take the dot product of unit importance and output sequences of LSTM to get Attention scores of each time step.
	\item Take the dot product of Attention scores and the output sequences of LSTM to get attention vector.
	\item Add an additional FC Layer and then to output Layer with SoftMax Activation.
	
\end{enumerate}
\section{RUN:}
The Code is written using Google Colab:
\begin{enumerate}
	\item  Open ColabNotebook.ipynb and change Runtime to GPU.
	\item  Upload Speech-Recognition-Project/Data to Colab.
	\item Run the cells in the same order in Notebook Test.
\end{enumerate}
\section{TEST:}
\begin{enumerate}
	\item  Locate the folder where you save your model.h5 file.
	\item  Start speaking when you see mike in the bottom right plane of the task bar
	or see red blinking dot in the title bar.
\end{enumerate}
\section{MODEL SUMMARY:}
\begin{figure}[htp]
	\centering
	\includegraphics[width=10cm]{model.png}
	\caption{Fig}
\end{figure}
\newpage
\section{The model is accomplished with an maximum accuracy of $97.8\%$.}
\end{document}